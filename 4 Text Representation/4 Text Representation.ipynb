{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5659bb8c-187a-4feb-aa5b-e3ab94ceb6c3",
   "metadata": {},
   "source": [
    "# TEXT REPRESENTATION - NLP LECTURE 4\n",
    "## Bag of Words | Tf-Idf | N-grams, Bi-grams and Uni-grams | OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436d0c2f-d200-4dad-ba3f-a886d4a47f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205f0b97-8e76-40ee-aafe-04cabdc5d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame with 'text' and 'output' columns\n",
    "df = pd.DataFrame({'text': ['people watch campusx',\n",
    "                            'campusx watch campusx',\n",
    "                            'people write comment',\n",
    "                            'campusx write comment'],\n",
    "                   'output': [1, 1, 0, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecc0a04-3069-4cf1-a010-cf5e8b385cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6bcd10-9b64-4140-9ca0-bf06051f519b",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979700f-d158-494f-92a8-74a27ff61df5",
   "metadata": {},
   "source": [
    "### Using :  sklearn - CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf5bfc6-b78d-4c73-823f-4ec0bf9d72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the CountVectorizer module\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initializing the CountVectorizer object with desired parameters\n",
    "cv = CountVectorizer(\n",
    "    lowercase=True,  # Convert all characters to lowercase before tokenizing\n",
    "    binary=False,    # Set binary=True for problems like sentiment analysis\n",
    "    max_features=None  # If not None, build a vocabulary that only considers \n",
    "                       # the top max_features ordered by term frequency across\n",
    "                       # the corpus. Otherwise, all features are used.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339cbede-6558-4518-b5d5-568e56897b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the 'text' column of the DataFrame using the CountVectorizer\n",
    "bow = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9fa0655-f864-436e-b362-e3a4ff0a901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "# Printing the vocabulary\n",
    "\n",
    "# The 'cv.vocabulary_' attribute contains a dictionary where the keys are the unique words \n",
    "# in the documents and the values are the corresponding indices assigned to each word.\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0862e032-5171-487b-8634-737f8bf88d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[2 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Converting sparse matrix to array\n",
    "\n",
    "# The 'toarray()' method is used to convert the sparse matrix 'bow[0]' \n",
    "# to a dense array representation.\n",
    "\n",
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1b244-4c2f-4c53-b7af-58ab4ef4b84e",
   "metadata": {},
   "source": [
    "#### out of vocab problem is handled here \n",
    "\n",
    "see how and,of, and other words are handled below \n",
    "they were absent during the training time # Handling Out-of-Vocabulary (OOV) problem When using CountVectorizer, the vocabulary is built based on the words present in the training data. \n",
    "If there are words in the test data that were not present during training,they will not be included in the vocabulary.\n",
    "\n",
    "Let's see how the words \"other\" and \"book\" are handled below:\n",
    "Since these words were absent during the training time, they will not be present in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92b2590-e1cb-4f87-a488-c47ad5804cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(cv.transform([\"write other book \"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af829f93-7a8c-4aa0-8746-3f46ab25ee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379b690-e1b9-4737-9d3b-92b532f2d6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b366ea5c-810c-4931-81f1-57d64f05e5ab",
   "metadata": {},
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1b8192-3e13-4bba-9664-0f73dc0a002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people watch': 2, 'watch campusx': 4, 'campusx watch': 0, 'people write': 3, 'write comment': 5, 'campusx write': 1}\n"
     ]
    }
   ],
   "source": [
    "# Importing the required library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initializing the CountVectorizer object with desired parameters\n",
    "cv = CountVectorizer(\n",
    "    ngram_range=(2, 2)  # Using bigrams (ngram_range=(2, 2))\n",
    ")\n",
    "\n",
    "# Applying CountVectorizer to the 'text' column in the DataFrame 'df'\n",
    "bigram = cv.fit_transform(df['text'])\n",
    "\n",
    "# Printing the vocabulary\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7566749-30e0-4ba1-b6d0-a1a59d15c28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51ccf831-1add-41c1-b9eb-6a97276c780e",
   "metadata": {},
   "source": [
    "### Using n-grams of size 1 to 3 (unigrams, bigrams, and trigrams) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04533b75-aefb-45e8-88e7-37a4162e0829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 6, 'watch': 11, 'campusx': 0, 'people watch': 7, 'watch campusx': 12, 'people watch campusx': 8, 'campusx watch': 1, 'campusx watch campusx': 2, 'write': 13, 'comment': 5, 'people write': 9, 'write comment': 14, 'people write comment': 10, 'campusx write': 3, 'campusx write comment': 4}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Importing the required library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initializing the CountVectorizer object with desired parameters\n",
    "cv = CountVectorizer(\n",
    "    ngram_range=(1, 3)  # Using n-grams of size 1 to 3 (unigrams, bigrams, and trigrams)\n",
    ")\n",
    "\n",
    "# Applying CountVectorizer to the 'text' column in the DataFrame 'df'\n",
    "ngram = cv.fit_transform(df['text'])\n",
    "\n",
    "# Printing the vocabulary (unique words and n-grams in the text corpus)\n",
    "print(cv.vocabulary_)\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d161e62-dfa2-4196-ad9f-59ec8efad30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67825b-f433-48cf-a2e7-d35ce0ebfa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55274383-e45f-4b75-8296-5550e54922dd",
   "metadata": {},
   "source": [
    "## Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee7bc878-c790-4f56-b6b0-6f275010e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49681612 0.         0.61366674 0.61366674 0.        ]\n",
      " [0.8508161  0.         0.         0.52546357 0.        ]\n",
      " [0.         0.57735027 0.57735027 0.         0.57735027]\n",
      " [0.49681612 0.61366674 0.         0.         0.61366674]]\n"
     ]
    }
   ],
   "source": [
    "# Importing the required library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initializing the TfidfVectorizer object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fitting and transforming the 'text' column in the DataFrame 'df'  \n",
    "# into TF-IDF vectors\n",
    "tfidf_matrix = tfidf.fit_transform(df['text']).toarray()\n",
    "\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3ce2ce2-a240-436d-a5d1-09d19c363a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.51082562 1.51082562]\n",
      "['campusx' 'comment' 'people' 'watch' 'write']\n"
     ]
    }
   ],
   "source": [
    "# Printing the inverse document frequency (IDF) of each feature in the \n",
    "# TfidfVectorizer\n",
    "print(tfidf.idf_)\n",
    "\n",
    "# Printing the feature names (words) in the TfidfVectorizer\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d93a0-9683-4f64-ac9c-11da2f34008b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15fe21d-f809-42c3-b8e2-dabb07b651cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea59b7a-c089-439e-ac74-7b874826ed24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e83268-07bb-4e9e-be93-0c2cd1538a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
